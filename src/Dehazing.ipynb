{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the cv2 library\n",
    "import cv2\n",
    "\n",
    "# The function cv2.imread() is used to read an image.\n",
    "img = cv2.imread('D:/EntornosPython/imgs/cell.png')\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# The function cv2.imshow() is used to display an image in a window.\n",
    "cv2.imshow('BGR image',img)\n",
    "\n",
    "# waitKey() waits for a key press to close the window and 0 specifies indefinite loops\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows() simply destroys all the windows we created.\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# The function cv2.imwrite() is used to write an image.\n",
    "#cv2.imwrite('grayscale.jpg',img_grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, g, r = cv2.split (img) # El orden es b, g, r, no r, g, b\n",
    "merged = cv2.merge([b,g,r])\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.imshow(\"Blue 1\", b)\n",
    "cv2.imshow(\"Green 1\", g)\n",
    "cv2.imshow(\"Red 1\", r)\n",
    "cv2.imshow(\"merged 1\", merged)\n",
    "cv2.waitKey (0) #Asegúrese de agregar cv2.waitKey (0), de lo contrario se informará un error\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 259, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "h,w,c = img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv(r, g, b):\n",
    "    r = float(r)\n",
    "    g = float(g)\n",
    "    b = float(b)\n",
    "    high = max(r, g, b)\n",
    "    low = min(r, g, b)\n",
    "    h, s, v = high, high, high\n",
    "\n",
    "    d = high - low\n",
    "    s = 0 if high == 0 else d/high\n",
    "\n",
    "    if high == low:\n",
    "        h = 0.0\n",
    "    else:\n",
    "        h = {\n",
    "            r: ((g - b) / d) % 6,\n",
    "            g: (b - r) / d + 2,\n",
    "            b: (r - g) / d + 4,\n",
    "        }[high]\n",
    "        h /= 6\n",
    "\n",
    "    return h, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resutlHSVown = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSVown(img,resutlHSVown,h,w):\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            b = img[i][j][0]\n",
    "            g = img[i][j][1]\n",
    "            r = img[i][j][2]\n",
    "            h,s,v = rgb_to_hsv(r,g,b)\n",
    "            #print(h)\n",
    "            resutlHSVown[i][j][0] = h\n",
    "            resutlHSVown[i][j][1] = s\n",
    "            resutlHSVown[i][j][2] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h,s,v = cv2.split (resutlHSVown)\n",
    "merged = cv2.merge([h,s,v])\n",
    "\n",
    "cv2.imshow(\"Hue 1\", h)\n",
    "cv2.imshow(\"Saturation 1\", s)\n",
    "cv2.imshow(\"Valor 1\", v)\n",
    "cv2.imshow(\"merged 1\", merged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hsvImg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split (hsvImg)\n",
    "merged = cv2.merge([h,s,v])\n",
    "\n",
    "cv2.imshow(\"Hue 1\", h)\n",
    "cv2.imshow(\"Saturation 1\", s)\n",
    "cv2.imshow(\"Valor 1\", v)\n",
    "cv2.imshow(\"merged 1\", merged)\n",
    "\n",
    "\n",
    "#cv2.imshow('RGB image', img)\n",
    "#cv2.imshow('HSV image', hsvImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propuestas de algoritmos de HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagen con Niebla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv\n",
    "from skimage.util import img_as_float64\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 2940, 3)\n",
      "(504, 735, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('D:/EntornosPython/imgs/Middlebury_Hazy/Backpack_Hazy.bmp')\n",
    "\n",
    "print(img.shape)\n",
    "# let's downscale the image using new  width and height\n",
    "down_width = 735\n",
    "down_height = 504\n",
    "down_points = (down_width, down_height)\n",
    "img_resized = cv2.resize(img, down_points, interpolation= cv2.INTER_LINEAR)\n",
    "print(img_resized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HSV colour space\n",
    "## HSV ONW\n",
    "resutlHSVown = img_resized.copy()\n",
    "h,w,c = img_resized.shape\n",
    "HSVown(img_resized,resutlHSVown,h,w)    \n",
    "\n",
    "\n",
    "## HSV openCV\n",
    "resultCV = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HSV Skimage\n",
    "img_resized = img_as_float64(img_resized)\n",
    "resultSkimage = rgb2hsv(img_resized)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image Original\",img_resized)\n",
    "cv2.imshow(\"HSV using skimage\",resultSkimage)\n",
    "cv2.imshow(\"HSV using openCV\",resultCV)\n",
    "cv2.imshow(\"HSV using my own implementation\",resutlHSVown)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_H,channel_S,channel_V = cv2.split (resultCV)\n",
    "merged = cv2.merge([channel_H,channel_S,channel_V])\n",
    "\n",
    "cv2.imshow(\"Hue 1\", channel_H)\n",
    "cv2.imshow(\"Saturation 1\", channel_S)\n",
    "cv2.imshow(\"Valor 1\", channel_V)\n",
    "cv2.imshow(\"merged 1\", merged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagen Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 2940, 3)\n",
      "(504, 735, 3)\n"
     ]
    }
   ],
   "source": [
    "imgReal = cv2.imread('D:/EntornosPython/imgs/Middlebury_GT/Backpack_im0.png')\n",
    "print(imgReal.shape)\n",
    "# let's downscale the image using new  width and height\n",
    "down_width = 735\n",
    "down_height = 504\n",
    "down_points = (down_width, down_height)\n",
    "img_resizedReal = cv2.resize(imgReal, down_points, interpolation= cv2.INTER_LINEAR)\n",
    "print(img_resizedReal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HSV colour space\n",
    "## HSV ONW\n",
    "resutlHSVownReal = img_resizedReal.copy()\n",
    "h,w,c = img_resizedReal.shape\n",
    "HSVown(img_resizedReal,resutlHSVownReal,h,w)    \n",
    "\n",
    "\n",
    "## HSV openCV\n",
    "resultCVReal = cv2.cvtColor(img_resizedReal, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HSV Skimage\n",
    "img_resizedReal = img_as_float64(img_resizedReal)\n",
    "resultSkimageReal = rgb2hsv(img_resizedReal)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image Original\",img_resizedReal)\n",
    "cv2.imshow(\"HSV using skimage\",resultSkimageReal)\n",
    "cv2.imshow(\"HSV using openCV\",resultCVReal)\n",
    "cv2.imshow(\"HSV using my own implementation\",resutlHSVownReal)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelReal_H,channelReal_S,channelReal_V = cv2.split (resultCVReal)\n",
    "mergedReal = cv2.merge([channelReal_H,channelReal_S,channelReal_V])\n",
    "\n",
    "cv2.imshow(\"Hue 1\", channelReal_H)\n",
    "cv2.imshow(\"Saturation 1\", channelReal_S)\n",
    "cv2.imshow(\"Valor 1\", channelReal_V)\n",
    "cv2.imshow(\"merged 1\", mergedReal)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion entre del canales HUE,Valor,Saturacion de las imágenes con niebla y las imágenes reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separacion de canales en imagen con niebla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Hue Ground Truth\", channelReal_H)\n",
    "cv2.imshow(\"Hue Hazy\", channel_H)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Value Ground Truth\", channelReal_V)\n",
    "cv2.imshow(\"Value Hazy\", channel_V)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Saturation Ground Truth\", channelReal_S)\n",
    "cv2.imshow(\"Saturation Hazy\", channel_S)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM: 0.9870807377968952\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute SSIM between two images\n",
    "(score, diff) = ssim(channelReal_H, channel_H, full=True)\n",
    "#print(\"Image similarity\", score)\n",
    "print(\"SSIM: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The diff image contains the actual image differences between the two images\n",
    "# and is represented as a floating point data type in the range [0,1] \n",
    "# so we must convert the array to 8-bit unsigned integers in the range\n",
    "# [0,255] before we can use it with OpenCV\n",
    "diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "# Threshold the difference image, followed by finding contours to\n",
    "# obtain the regions of the two input images that differ\n",
    "thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "cv2.imshow('before', channelReal_H)\n",
    "cv2.imshow('after', channel_H)\n",
    "cv2.imshow('diff',thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTENSITY RECOVERY BY OPENING OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 2940, 3)\n",
      "(504, 735, 3)\n"
     ]
    }
   ],
   "source": [
    "imgBackpack = cv2.imread('D:/EntornosPython/imgs/Middlebury_Hazy/Backpack_Hazy.bmp')\n",
    "\n",
    "print(img.shape)\n",
    "# let's downscale the image using new  width and height\n",
    "down_width = 735\n",
    "down_height = 504\n",
    "down_points = (down_width, down_height)\n",
    "img_resizedB = cv2.resize(imgBackpack, down_points, interpolation= cv2.INTER_LINEAR)\n",
    "print(img_resizedB.shape)\n",
    "\n",
    "cv2.imshow('Ground Truth',img_resizedB )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate minimum value in RGB channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/minimumchannel.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinChannel(img):\n",
    "    if len(img.shape)==3 and img.shape[2]==3:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"bad image shape, input must be color image\")\n",
    "        return None\n",
    "    \n",
    "    return np.min(img, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "minChannel = getMinChannel(img_resizedB)\n",
    "cv2.imshow('minChannel',minChannel )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216 238 248]\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "print(img_resizedB[0][0])\n",
    "print(minChannel[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Dark Channel Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDarkChannel(img,blockSize = 3):\n",
    "\n",
    "    \n",
    "    if len(img.shape)==2:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"bad image shape, input image must be two demensions\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "    if blockSize % 2 == 0 or blockSize < 3:\n",
    "        print('blockSize is not odd or too small')\n",
    "        return None\n",
    "\n",
    "    # addSize\n",
    "    A = int((blockSize-1)/2) #AddSize\n",
    "\n",
    "    #New height and new width\n",
    "    H = img.shape[0] + blockSize - 1\n",
    "    W = img.shape[1] + blockSize - 1\n",
    "\n",
    "    # 中间结果\n",
    "    imgMiddle = 255 * np.ones((H,W))    \n",
    "\n",
    "    imgMiddle[A:H-A, A:W-A] = img\n",
    "    \n",
    "    imgDark = np.zeros_like(img, np.uint8)    \n",
    "    \n",
    "    localMin = 255\n",
    "    for i in range(A, H-A):\n",
    "        for j in range(A, W-A):\n",
    "            x = range(i-A, i+A+1)\n",
    "            y = range(j-A, j+A+1)\n",
    "            imgDark[i-A,j-A] = np.min(imgMiddle[x,y])                            \n",
    "            \n",
    "    return imgDark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(504, 735)\n"
     ]
    }
   ],
   "source": [
    "print(minChannel.dtype)\n",
    "print(minChannel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213 214 213 ... 186 188 192]\n",
      " [213 213 214 ... 189 186 188]\n",
      " [213 213 213 ... 187 189 186]\n",
      " ...\n",
      " [201 196 199 ... 189 187 180]\n",
      " [205 201 196 ... 183 189 187]\n",
      " [211 205 201 ... 188 183 189]]\n"
     ]
    }
   ],
   "source": [
    "DCPimage = getDarkChannel(minChannel,15)\n",
    "print(DCPimage)\n",
    "cv2.imshow('DCPimage ',DCPimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare minimun value and DCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Minimumimage ',minChannel)\n",
    "cv2.imshow('DCPimage ',DCPimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified morphological opening operation to Imin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/modifiedoperationmodificada.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regla de 3 simple es (13,7)\n",
    "  \n",
    "kernelR1 = np.ones((7,7), np.uint8)  \n",
    "img_erosion = cv2.erode(minChannel, kernelR1, iterations=1)  \n",
    "\n",
    "kernelR2 = np.ones((13,13), np.uint8)  \n",
    "img_dilation = cv2.dilate(img_erosion, kernelR2, iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_open = img_dilation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slightest(img1,img2):\n",
    "    if len(img1.shape)==2 and len(img2.shape)==2:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"bad image shape, input must be gray image\")\n",
    "        return None\n",
    "    return np.minimum(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imodify = slightest(minChannel,img_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216 214 217 ... 186 188 192]\n",
      " [216 214 216 ... 189 190 193]\n",
      " [215 215 216 ... 187 190 194]\n",
      " ...\n",
      " [205 203 215 ... 196 187 180]\n",
      " [205 201 196 ... 183 196 198]\n",
      " [211 213 212 ... 188 188 190]]\n",
      "[[214 214 214 ... 185 185 185]\n",
      " [214 214 214 ... 185 185 185]\n",
      " [214 214 214 ... 185 185 185]\n",
      " ...\n",
      " [197 197 197 ... 189 189 189]\n",
      " [197 197 197 ... 189 189 189]\n",
      " [197 197 197 ... 189 189 189]]\n",
      "[[214 214 214 ... 185 185 185]\n",
      " [214 214 214 ... 185 185 185]\n",
      " [214 214 214 ... 185 185 185]\n",
      " ...\n",
      " [197 197 197 ... 189 187 180]\n",
      " [197 197 196 ... 183 189 189]\n",
      " [197 197 197 ... 188 188 189]]\n"
     ]
    }
   ],
   "source": [
    "print(minChannel)\n",
    "print(img_open)\n",
    "print(Imodify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Min Channel', minChannel)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "cv2.imshow('Dilation', img_dilation)\n",
    "cv2.imshow('slightestImg', Imodify)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain global atmospheric light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/atmosfericLight.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/get10percent.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,x,y,value):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.value = value\n",
    "\n",
    "    def printInfo(self):\n",
    "        print('%s:%s:%s' %(self.x,self.y,self.value))\n",
    "\n",
    "def getAtomsphericLight(darkChannel,img,meanMode = False, percent = 0.001):\n",
    "    \n",
    "    size = darkChannel.shape[0]*darkChannel.shape[1]\n",
    "    height = darkChannel.shape[0]\n",
    "    width = darkChannel.shape[1]\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    #\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            oneNode = Node(i,j,darkChannel[i,j])\n",
    "            nodes.append(oneNode)\t\n",
    "\n",
    "    #\n",
    "    nodes = sorted(nodes, key = lambda node: node.value,reverse = True)\n",
    "    # print(nodes[0].value)\n",
    "    # print(nodes[1].value)\n",
    "    # print(nodes[2].value)\n",
    "    # print(nodes[3].value)\n",
    "    # print(nodes[4].value)\n",
    "    # print(nodes[len(nodes)-1].value)\n",
    "\n",
    "    atomsphericLight = 0\n",
    "\n",
    "    # #\n",
    "    if int(percent*size) == 0:\n",
    "        for i in range(3):\n",
    "            if img[nodes[0].x,nodes[0].y,i] > atomsphericLight:\n",
    "                atomsphericLight = img[nodes[0].x,nodes[0].y,i]\n",
    "        return atomsphericLight\n",
    "\n",
    "    # #\n",
    "    # if meanMode:\n",
    "    #     sum = 0\n",
    "    #     for i in range(0,int(percent*size)):\n",
    "    #         for j in range(0,3):\n",
    "    #             sum = sum + img[nodes[i].x,nodes[i].y,j]\n",
    "    #     atomsphericLight = int(sum/(int(percent*size)*3))\n",
    "    #     return atomsphericLight\n",
    "\n",
    "    #0.1%(percent)\n",
    "    for i in range(int(percent*size)):\n",
    "        for j in range(3):\n",
    "            if img[nodes[i].x,nodes[i].y,j] > atomsphericLight:\n",
    "                atomsphericLight = img[nodes[i].x,nodes[i].y,j]\n",
    "    return atomsphericLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "# atomspheric Light\n",
    "A_ = getAtomsphericLight(Imodify,img_resizedB, percent = 0.1)\n",
    "print(A_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Transmision Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/TransmisionMap.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgDark = np.float64(Imodify)\n",
    "omega = 0.9 #ω is used to preserve distant haze, usually fixed as 0.9.\n",
    "transmission = 1 - (omega * (imgDark / A_))\n",
    "transmission_for_Saturation = transmission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " [0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " [0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " ...\n",
      " [0.30470588 0.30470588 0.30470588 ... 0.33294118 0.34       0.36470588]\n",
      " [0.30470588 0.30470588 0.30823529 ... 0.35411765 0.33294118 0.33294118]\n",
      " [0.30470588 0.30470588 0.30470588 ... 0.33647059 0.33647059 0.33294118]]\n"
     ]
    }
   ],
   "source": [
    "print(transmission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover the value channel (Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/RecoverIntensity.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 0.1\n",
    "transmission[transmission<t0] = t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " [0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " [0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " ...\n",
      " [0.30470588 0.30470588 0.30470588 ... 0.33294118 0.34       0.36470588]\n",
      " [0.30470588 0.30470588 0.30823529 ... 0.35411765 0.33294118 0.33294118]\n",
      " [0.30470588 0.30470588 0.30470588 ... 0.33647059 0.33647059 0.33294118]]\n"
     ]
    }
   ],
   "source": [
    "print(transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "channel_VFloat = np.float64(channel_V)\n",
    "numeratorR = abs(channel_VFloat - A_)\n",
    "denominatorR = transmission\n",
    "print(channel_V.dtype)\n",
    "print(channel_VFloat.dtype)\n",
    "print(numeratorR.dtype)\n",
    "print(denominatorR.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoValue = A_ + (numeratorR/denominatorR)\n",
    "recoValue = np.uint8(recoValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27  31  23 ...  45  42  36]\n",
      " [ 27  31  31 ...  39  42  33]\n",
      " [ 27  31  31 ...  42  45  33]\n",
      " ...\n",
      " [ 84  94  67 ... 116 149 147]\n",
      " [ 90 107 122 ... 143 104  98]\n",
      " [ 74  61  71 ... 123 120 122]]\n"
     ]
    }
   ],
   "source": [
    "print(recoValue)\n",
    "cv2.imshow('channel V Retrieved', recoValue)\n",
    "recoValueInv = abs(255-recoValue)\n",
    "cv2.imshow('channel V Retrieved Inverso', recoValueInv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('channel V Real', channelReal_V) #canal a donde se quiere llegar (Y)\n",
    "cv2.imshow('channel V Retrieved', recoValue)\n",
    "cv2.imshow('channel V Retrieved Inverso', recoValueInv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SATURATION RECOVERY MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/Saturationrecovery.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value channel in HSV color space is the maximum image of RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(transmission_for_Saturation.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " [0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " [0.24470588 0.24470588 0.24470588 ... 0.34705882 0.34705882 0.34705882]\n",
      " ...\n",
      " [0.30470588 0.30470588 0.30470588 ... 0.33294118 0.34       0.36470588]\n",
      " [0.30470588 0.30470588 0.30823529 ... 0.35411765 0.33294118 0.33294118]\n",
      " [0.30470588 0.30470588 0.30470588 ... 0.33647059 0.33647059 0.33294118]]\n"
     ]
    }
   ],
   "source": [
    "print(transmission_for_Saturation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24470588 -0.24470588 -0.24470588 ... -0.34705882 -0.34705882\n",
      "  -0.34705882]\n",
      " [-0.24470588 -0.24470588 -0.24470588 ... -0.34705882 -0.34705882\n",
      "  -0.34705882]\n",
      " [-0.24470588 -0.24470588 -0.24470588 ... -0.34705882 -0.34705882\n",
      "  -0.34705882]\n",
      " ...\n",
      " [-0.30470588 -0.30470588 -0.30470588 ... -0.33294118 -0.34\n",
      "  -0.36470588]\n",
      " [-0.30470588 -0.30470588 -0.30823529 ... -0.35411765 -0.33294118\n",
      "  -0.33294118]\n",
      " [-0.30470588 -0.30470588 -0.30470588 ... -0.33647059 -0.33647059\n",
      "  -0.33294118]]\n"
     ]
    }
   ],
   "source": [
    "transmission_for_Saturation = transmission_for_Saturation - 1\n",
    "print(transmission_for_Saturation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "[0.84705882 0.93333333 0.97254902]\n"
     ]
    }
   ],
   "source": [
    "#comprobando que V es el maximo de RGB\n",
    "print(channel_V[0][0])\n",
    "print(img_resized[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximumRGB = channel_V\n",
    "equation_1 = A_ * transmission_for_Saturation\n",
    "equation_2 = equation_1/maximumRGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(equation_2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoSaturation = channel_S * (1/(1+equation_2))\n",
    "recoSaturation = np.uint8(recoSaturation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('channel S Retrieved', recoSaturation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion S y S recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('channel S Real', channelReal_S) #canal a donde se quiere llegar (Y)\n",
    "cv2.imshow('channel S hazy', channel_S)\n",
    "cv2.imshow('channel S Retrieved', recoSaturation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('EntornosPython': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e4d18e1d7a67e59aba8635045baf57205cbeb42dd86a6aadf2b78c4ac7f4a8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
