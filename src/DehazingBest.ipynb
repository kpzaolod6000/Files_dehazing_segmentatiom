{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROPOSED ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/workflow.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv(r, g, b):\n",
    "    r = float(r)\n",
    "    g = float(g)\n",
    "    b = float(b)\n",
    "    high = max(r, g, b)\n",
    "    low = min(r, g, b)\n",
    "    h, s, v = high, high, high\n",
    "\n",
    "    d = high - low\n",
    "    s = 0 if high == 0 else d/high\n",
    "\n",
    "    if high == low:\n",
    "        h = 0.0\n",
    "    else:\n",
    "        h = {\n",
    "            r: ((g - b) / d) % 6,\n",
    "            g: (b - r) / d + 2,\n",
    "            b: (r - g) / d + 4,\n",
    "        }[high]\n",
    "        h /= 6\n",
    "\n",
    "    return h, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSVown(img,resutlHSVown,h,w):\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            b = img[i][j][0]\n",
    "            g = img[i][j][1]\n",
    "            r = img[i][j][2]\n",
    "            h,s,v = rgb_to_hsv(r,g,b)\n",
    "            #print(h)\n",
    "            resutlHSVown[i][j][0] = h\n",
    "            resutlHSVown[i][j][1] = s\n",
    "            resutlHSVown[i][j][2] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propuestas de algoritmos de HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagen con Niebla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv\n",
    "from skimage.util import img_as_float64\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2833, 4657, 3)\n",
      "(480, 705, 3)\n"
     ]
    }
   ],
   "source": [
    "#img = cv2.imread('D:/EntornosPython/imgs/Middlebury_Hazy/Piano_Hazy.bmp')\n",
    "#img = cv2.imread('D:/EntornosPython/imgs/Fog/6726971629.png')\n",
    "#img = cv2.imread('D:/EntornosPython/imgs/Data_Landscape/hazy/55_hazy.png')\n",
    "img = cv2.imread('D:/EntornosPython/imgs/HAZY_NTIRE_2018/hazy/17_indoor_hazy.jpg')\n",
    " \n",
    "print(img.shape)\n",
    "# let's downscale the image using new  width and height\n",
    "down_width = 705#735\n",
    "down_height = 480#504\n",
    "down_points = (down_width, down_height)\n",
    "img_resized = cv2.resize(img, down_points, interpolation= cv2.INTER_LINEAR)\n",
    "print(img_resized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(img_resized.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[220 215 213]\n",
      "  [213 207 202]\n",
      "  [215 209 204]\n",
      "  ...\n",
      "  [195 194 196]\n",
      "  [195 196 194]\n",
      "  [195 196 194]]\n",
      "\n",
      " [[218 213 209]\n",
      "  [216 211 206]\n",
      "  [215 209 204]\n",
      "  ...\n",
      "  [193 195 196]\n",
      "  [195 196 194]\n",
      "  [197 194 193]]\n",
      "\n",
      " [[218 212 207]\n",
      "  [216 210 205]\n",
      "  [216 210 205]\n",
      "  ...\n",
      "  [195 196 194]\n",
      "  [194 195 193]\n",
      "  [195 195 193]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[108 101  98]\n",
      "  [106 100  97]\n",
      "  [122 115 112]\n",
      "  ...\n",
      "  [ 62  60  59]\n",
      "  [ 60  58  57]\n",
      "  [ 60  58  58]]\n",
      "\n",
      " [[109 101  98]\n",
      "  [108 100  97]\n",
      "  [106  98  95]\n",
      "  ...\n",
      "  [ 60  58  58]\n",
      "  [ 61  59  58]\n",
      "  [ 61  59  58]]\n",
      "\n",
      " [[112 105 102]\n",
      "  [105 100  96]\n",
      "  [107 101  98]\n",
      "  ...\n",
      "  [ 61  59  59]\n",
      "  [ 62  60  60]\n",
      "  [ 63  61  61]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HSV colour space\n",
    "\n",
    "\n",
    "## HSV ONW\n",
    "resutlHSVown = img_resized.copy()\n",
    "h,w,c = img_resized.shape\n",
    "HSVown(img_resized,resutlHSVown,h,w)    \n",
    "\n",
    "## HSV openCV\n",
    "resultCV = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HSV Skimage\n",
    "img_resizedfloat = img_as_float64(img_resized)\n",
    "resultSkimage = rgb2hsv(img_resizedfloat)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image Original\",img_resized)\n",
    "cv2.imshow(\"HSV using skimage\",resultSkimage)\n",
    "cv2.imshow(\"HSV using openCV\",resultCV)\n",
    "cv2.imshow(\"HSV using my own implementation\",resutlHSVown)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(resultCV.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_H,channel_S,channel_V = cv2.split (resultCV)\n",
    "merged = cv2.merge([channel_H,channel_S,channel_V])\n",
    "\n",
    "cv2.imshow(\"Hue 1\", channel_H)\n",
    "cv2.imshow(\"Saturation 1\", channel_S)\n",
    "cv2.imshow(\"Valor 1\", channel_V)\n",
    "cv2.imshow(\"merged 1\", merged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagen Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2833, 4657, 3)\n",
      "(480, 705, 3)\n"
     ]
    }
   ],
   "source": [
    "#imgReal = cv2.imread('D:/EntornosPython/imgs/Middlebury_GT/Piano_im0.png')\n",
    "#imgReal = cv2.imread('D:/EntornosPython/imgs/Fog/827916289.png')\n",
    "#imgReal = cv2.imread('D:/EntornosPython/imgs/Data_Landscape/GT/55_GT.png')\n",
    "imgReal = cv2.imread('D:/EntornosPython/imgs/HAZY_NTIRE_2018/GT/17_indoor_GT.jpg')\n",
    "print(imgReal.shape)\n",
    "\n",
    "# let's downscale the image using new  width and height\n",
    "down_width = 705#735\n",
    "down_height = 480#504\n",
    "down_points = (down_width, down_height)\n",
    "img_resizedReal = cv2.resize(imgReal, down_points, interpolation= cv2.INTER_LINEAR)\n",
    "print(img_resizedReal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(img_resizedReal.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HSV colour space\n",
    "## HSV ONW\n",
    "resutlHSVownReal = img_resizedReal.copy()\n",
    "h_,w_,c_ = img_resizedReal.shape\n",
    "HSVown(img_resizedReal,resutlHSVownReal,h_,w_)    \n",
    "\n",
    "\n",
    "## HSV openCV\n",
    "resultCVReal = cv2.cvtColor(img_resizedReal, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HSV Skimage\n",
    "img_resizedReal = img_as_float64(img_resizedReal)\n",
    "resultSkimageRealFloat = rgb2hsv(img_resizedReal)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image Original\",img_resizedReal)\n",
    "cv2.imshow(\"HSV using skimage\",resultSkimageRealFloat)\n",
    "cv2.imshow(\"HSV using openCV\",resultCVReal)\n",
    "cv2.imshow(\"HSV using my own implementation\",resutlHSVownReal)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelReal_H,channelReal_S,channelReal_V = cv2.split (resultCVReal)\n",
    "mergedReal = cv2.merge([channelReal_H,channelReal_S,channelReal_V])\n",
    "\n",
    "cv2.imshow(\"Hue 1\", channelReal_H)\n",
    "cv2.imshow(\"Saturation 1\", channelReal_S)\n",
    "cv2.imshow(\"Valor 1\", channelReal_V)\n",
    "cv2.imshow(\"merged 1\", mergedReal)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion entre del canales HUE,Valor,Saturacion de las imágenes con niebla y las imágenes reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separacion de canales en imagen con niebla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Hue Ground Truth\", channelReal_H)\n",
    "cv2.imshow(\"Hue Hazy\", channel_H)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Value Ground Truth\", channelReal_V)\n",
    "cv2.imshow(\"Value Hazy\", channel_V)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Saturation Ground Truth\", channelReal_S)\n",
    "cv2.imshow(\"Saturation Hazy\", channel_S)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM: 0.22042788396591595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute SSIM between two images\n",
    "(score, diff) = ssim(channelReal_H, channel_H, full=True)\n",
    "#print(\"Image similarity\", score)\n",
    "print(\"SSIM: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The diff image contains the actual image differences between the two images\n",
    "# and is represented as a floating point data type in the range [0,1] \n",
    "# so we must convert the array to 8-bit unsigned integers in the range\n",
    "# [0,255] before we can use it with OpenCV\n",
    "diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "# Threshold the difference image, followed by finding contours to\n",
    "# obtain the regions of the two input images that differ\n",
    "thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "cv2.imshow('before', channelReal_H)\n",
    "cv2.imshow('after', channel_H)\n",
    "cv2.imshow('diff',thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTENSITY RECOVERY BY OPENING OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgBackpack = cv2.imread('D:/EntornosPython/imgs/Middlebury_Hazy/Backpack_Hazy.bmp')\n",
    "\n",
    "cv2.imshow('Ground Truth',img_resized )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate minimum value in RGB channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/minimumchannel.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinChannel(img):\n",
    "    if len(img.shape)==3 and img.shape[2]==3:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"bad image shape, input must be color image\")\n",
    "        return None\n",
    "    \n",
    "    return np.min(img, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "minChannel = getMinChannel(img_resized)\n",
    "cv2.imshow('minChannel',minChannel)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220 215 213]\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "print(img_resized[0][0])\n",
    "print(minChannel[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Dark Channel Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDarkChannel(img,blockSize = 3):\n",
    "\n",
    "    \n",
    "    if len(img.shape)==2:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"bad image shape, input image must be two demensions\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "    if blockSize % 2 == 0 or blockSize < 3:\n",
    "        print('blockSize is not odd or too small')\n",
    "        return None\n",
    "\n",
    "    # addSize\n",
    "    A = int((blockSize-1)/2) #AddSize\n",
    "\n",
    "    #New height and new width\n",
    "    H = img.shape[0] + blockSize - 1\n",
    "    W = img.shape[1] + blockSize - 1\n",
    "\n",
    "    # 中间结果\n",
    "    imgMiddle = 255 * np.ones((H,W))    \n",
    "\n",
    "    imgMiddle[A:H-A, A:W-A] = img\n",
    "    \n",
    "    imgDark = np.zeros_like(img, np.uint8)    \n",
    "    \n",
    "    localMin = 255\n",
    "    for i in range(A, H-A):\n",
    "        for j in range(A, W-A):\n",
    "            x = range(i-A, i+A+1)\n",
    "            y = range(j-A, j+A+1)\n",
    "            imgDark[i-A,j-A] = np.min(imgMiddle[x,y])                            \n",
    "            \n",
    "    return imgDark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(480, 705)\n"
     ]
    }
   ],
   "source": [
    "print(minChannel.dtype)\n",
    "print(minChannel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[202 201 200 ... 193 193 194]\n",
      " [201 202 201 ... 193 193 193]\n",
      " [202 201 201 ... 192 193 193]\n",
      " ...\n",
      " [ 97  95  98 ...  58  57  57]\n",
      " [ 96  97  95 ...  58  58  57]\n",
      " [102  96  97 ...  58  58  58]]\n"
     ]
    }
   ],
   "source": [
    "DCPimage = getDarkChannel(minChannel,15)\n",
    "print(DCPimage)\n",
    "cv2.imshow('DCPimage ',DCPimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare minimun value and DCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Minimumimage ',minChannel)\n",
    "cv2.imshow('DCPimage ',DCPimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified morphological opening operation to Imin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/modifiedoperationmodificada.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regla de 3 simple es (13,7) backpack\n",
    "#regla de 3 simple es (13,7) Piano\n",
    "  \n",
    "kernelR1 = np.ones((31,31), np.uint8)  \n",
    "img_erosion = cv2.erode(minChannel, kernelR1, iterations=1)  \n",
    "\n",
    "kernelR2 = np.ones((35,35), np.uint8)  \n",
    "img_dilation = cv2.dilate(img_erosion, kernelR2, iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_open = img_dilation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slightest(img1,img2):\n",
    "    if len(img1.shape)==2 and len(img2.shape)==2:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"bad image shape, input must be gray image\")\n",
    "        return None\n",
    "    return np.minimum(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imodify = slightest(minChannel,img_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213 202 204 ... 194 194 194]\n",
      " [209 206 204 ... 193 194 193]\n",
      " [207 205 205 ... 194 193 193]\n",
      " ...\n",
      " [ 98  97 112 ...  59  57  58]\n",
      " [ 98  97  95 ...  58  58  58]\n",
      " [102  96  98 ...  59  60  61]]\n",
      "[[199 199 199 ... 184 184 183]\n",
      " [199 199 199 ... 184 184 183]\n",
      " [199 199 199 ... 184 184 183]\n",
      " ...\n",
      " [ 97  97  97 ...  57  57  57]\n",
      " [ 97  97  97 ...  57  57  57]\n",
      " [ 96  96  96 ...  57  57  57]]\n",
      "[[199 199 199 ... 184 184 183]\n",
      " [199 199 199 ... 184 184 183]\n",
      " [199 199 199 ... 184 184 183]\n",
      " ...\n",
      " [ 97  97  97 ...  57  57  57]\n",
      " [ 97  97  95 ...  57  57  57]\n",
      " [ 96  96  96 ...  57  57  57]]\n"
     ]
    }
   ],
   "source": [
    "print(minChannel)\n",
    "print(img_open)\n",
    "print(Imodify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Min Channel', minChannel)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "cv2.imshow('Dilation', img_dilation)\n",
    "cv2.imshow('slightestImg', Imodify)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain global atmospheric light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/atmosfericLight.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/get10percent.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,x,y,value):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.value = value\n",
    "\n",
    "    def printInfo(self):\n",
    "        print('%s:%s:%s' %(self.x,self.y,self.value))\n",
    "\n",
    "def getAtomsphericLight(darkChannel,img,meanMode = False, percent = 0.001):\n",
    "    \n",
    "    size = darkChannel.shape[0]*darkChannel.shape[1]\n",
    "    height = darkChannel.shape[0]\n",
    "    width = darkChannel.shape[1]\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    #\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            oneNode = Node(i,j,darkChannel[i,j])\n",
    "            nodes.append(oneNode)\t\n",
    "\n",
    "    #\n",
    "    nodes = sorted(nodes, key = lambda node: node.value,reverse = True)\n",
    "    # print(nodes[0].value)\n",
    "    # print(nodes[1].value)\n",
    "    # print(nodes[2].value)\n",
    "    # print(nodes[3].value)\n",
    "    # print(nodes[4].value)\n",
    "    # print(nodes[len(nodes)-1].value)\n",
    "\n",
    "    atomsphericLight = 0\n",
    "\n",
    "    # #\n",
    "    if int(percent*size) == 0:\n",
    "        for i in range(3):\n",
    "            if img[nodes[0].x,nodes[0].y,i] > atomsphericLight:\n",
    "                atomsphericLight = img[nodes[0].x,nodes[0].y,i]\n",
    "        return atomsphericLight\n",
    "\n",
    "    # #\n",
    "    # if meanMode:\n",
    "    #     sum = 0\n",
    "    #     for i in range(0,int(percent*size)):\n",
    "    #         for j in range(0,3):\n",
    "    #             sum = sum + img[nodes[i].x,nodes[i].y,j]\n",
    "    #     atomsphericLight = int(sum/(int(percent*size)*3))\n",
    "    #     return atomsphericLight\n",
    "\n",
    "    #0.1%(percent)\n",
    "    for i in range(int(percent*size)):\n",
    "        for j in range(3):\n",
    "            if img[nodes[i].x,nodes[i].y,j] > atomsphericLight:\n",
    "                atomsphericLight = img[nodes[i].x,nodes[i].y,j]\n",
    "    return atomsphericLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(img_resized.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "# atomspheric Light\n",
    "A_ = getAtomsphericLight(Imodify,img_resized, percent = 0.1)\n",
    "print(A_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Transmision Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/TransmisionMap.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgDark = np.float64(Imodify)\n",
    "omega = 0.9 #ω is used to preserve distant haze, usually fixed as 0.9.\n",
    "transmission = 1 - (omega * (imgDark / A_))\n",
    "transmission_for_Saturation = transmission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " [0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " [0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " ...\n",
      " [0.65764706 0.65764706 0.65764706 ... 0.79882353 0.79882353 0.79882353]\n",
      " [0.65764706 0.65764706 0.66470588 ... 0.79882353 0.79882353 0.79882353]\n",
      " [0.66117647 0.66117647 0.66117647 ... 0.79882353 0.79882353 0.79882353]]\n"
     ]
    }
   ],
   "source": [
    "print(transmission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover the value channel (Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/RecoverIntensity.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 0.1\n",
    "transmission[transmission<t0] = t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " [0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " [0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " ...\n",
      " [0.65764706 0.65764706 0.65764706 ... 0.79882353 0.79882353 0.79882353]\n",
      " [0.65764706 0.65764706 0.66470588 ... 0.79882353 0.79882353 0.79882353]\n",
      " [0.66117647 0.66117647 0.66117647 ... 0.79882353 0.79882353 0.79882353]]\n"
     ]
    }
   ],
   "source": [
    "print(transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "channel_VFloat = np.float64(channel_V)\n",
    "numeratorR = channel_VFloat - A_\n",
    "denominatorR = transmission\n",
    "print(channel_V.dtype)\n",
    "print(channel_VFloat.dtype)\n",
    "print(numeratorR.dtype)\n",
    "print(denominatorR.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoValue = A_ + (numeratorR/denominatorR)\n",
    "recoValue = np.uint8(recoValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137 113 120 ...  86  86  88]\n",
      " [130 123 120 ...  86  86  91]\n",
      " [130 123 123 ...  86  83  85]\n",
      " ...\n",
      " [ 31  28  52 ...  13  10  10]\n",
      " [ 32  31  30 ...  10  12  12]\n",
      " [ 38  28  31 ...  12  13  14]]\n"
     ]
    }
   ],
   "source": [
    "print(recoValue)\n",
    "cv2.imshow('channel V Retrieved', recoValue)\n",
    "recoValueInv = abs(255-recoValue)\n",
    "cv2.imshow('channel V Retrieved Inverso', recoValueInv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('channel V Real', channelReal_V) #canal a donde se quiere llegar (Y)\n",
    "cv2.imshow('channel V Retrieved', recoValue)\n",
    "cv2.imshow('channel V Retrieved Inverso', recoValueInv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SATURATION RECOVERY MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/formula/Saturationrecovery.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value channel in HSV color space is the maximum image of RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "transmission_for_Saturation = transmission.copy()\n",
    "print(transmission_for_Saturation.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " [0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " [0.29764706 0.29764706 0.29764706 ... 0.35058824 0.35058824 0.35411765]\n",
      " ...\n",
      " [0.65764706 0.65764706 0.65764706 ... 0.79882353 0.79882353 0.79882353]\n",
      " [0.65764706 0.65764706 0.66470588 ... 0.79882353 0.79882353 0.79882353]\n",
      " [0.66117647 0.66117647 0.66117647 ... 0.79882353 0.79882353 0.79882353]]\n"
     ]
    }
   ],
   "source": [
    "print(transmission_for_Saturation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70235294 -0.70235294 -0.70235294 ... -0.64941176 -0.64941176\n",
      "  -0.64588235]\n",
      " [-0.70235294 -0.70235294 -0.70235294 ... -0.64941176 -0.64941176\n",
      "  -0.64588235]\n",
      " [-0.70235294 -0.70235294 -0.70235294 ... -0.64941176 -0.64941176\n",
      "  -0.64588235]\n",
      " ...\n",
      " [-0.34235294 -0.34235294 -0.34235294 ... -0.20117647 -0.20117647\n",
      "  -0.20117647]\n",
      " [-0.34235294 -0.34235294 -0.33529412 ... -0.20117647 -0.20117647\n",
      "  -0.20117647]\n",
      " [-0.33882353 -0.33882353 -0.33882353 ... -0.20117647 -0.20117647\n",
      "  -0.20117647]]\n"
     ]
    }
   ],
   "source": [
    "transmission_for_Saturation = transmission_for_Saturation - 1\n",
    "print(transmission_for_Saturation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "[220 215 213]\n"
     ]
    }
   ],
   "source": [
    "#comprobando que V es el maximo de RGB\n",
    "print(channel_V[0][0])\n",
    "print(img_resized[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximumRGB = channel_V\n",
    "equation_1 = A_ * transmission_for_Saturation\n",
    "equation_2 = equation_1/maximumRGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 705)\n",
      "(480, 705)\n"
     ]
    }
   ],
   "source": [
    "print(maximumRGB.shape)\n",
    "print(equation_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(equation_2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_SFloat = np.float64(channel_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoSaturation = channel_SFloat * (1/(1+equation_2))\n",
    "recoSaturation = np.uint8(recoSaturation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('channel S Retrieved', recoSaturation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion S y S recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('channel S Real', channelReal_S) #canal a donde se quiere llegar (Y)\n",
    "cv2.imshow('channel S hazy', channel_S)\n",
    "cv2.imshow('channel S Retrieved', recoSaturation)\n",
    "\n",
    "recoSaturationInv = abs(255-recoSaturation)\n",
    "cv2.imshow('channel S Retrieved Inverso', recoSaturationInv)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mergedDehazing = cv2.merge([channel_H,recoSaturation,recoValue])\n",
    "bgrimg = cv2.cvtColor(mergedDehazing, cv2.COLOR_HSV2BGR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image Ground Truth\", img_resizedReal)\n",
    "cv2.imshow(\"Hazy Image\", img_resized)\n",
    "cv2.imshow(\"Dezahing Image \", bgrimg)\n",
    "cv2.waitKey (0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('EntornosPython': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e4d18e1d7a67e59aba8635045baf57205cbeb42dd86a6aadf2b78c4ac7f4a8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
